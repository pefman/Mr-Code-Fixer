# v1.2.0 Feature Summary

## Overview
Mr. Code Fixer v1.2.0 adds enterprise-grade features for cost control, quality assurance, and session tracking.

## New Features

### 1. Session Analytics ðŸ“Š
Track everything that happens during a bot session:
- **API Call Counting**: Every AI request is logged
- **Cost Tracking**: Real-time cost calculation based on service
- **Metrics Dashboard**: PRs created, issues handled, questions asked
- **Duration Tracking**: Know how long each session took

**Example Output:**
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                     ðŸ“Š Session Summary                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â±  Duration: 2m 34s
ðŸ¤– AI Calls: 5
ðŸ’° Estimated Cost: $0.005
ðŸ“ Issues Handled: 3
ðŸ”€ PRs Created: 2
â“ Questions Asked: 1
```

### 2. Cost Estimation ðŸ’°
Never be surprised by API costs again:
- **Pre-Processing Estimates**: Shows cost before processing multiple issues
- **Per-Service Pricing**: Different rates for ChatGPT ($0.002), Grok ($0.001), Ollama ($0)
- **Warning Threshold**: Highlights costs over $0.10
- **Smart Calculation**: Estimates 1.5x API calls per issue (accounting for retries)

**Example Output:**
```
ðŸ’° Estimated cost for 10 issues: ~$0.015 (15 AI calls @ $0.001 each)
âš ï¸  Note: Processing multiple issues will incur API costs
Fix all 10 issues? (yes/no) [no]:
```

### 3. Test Execution ðŸ§ª
Ensure fixes don't break existing functionality:
- **Auto-Detection**: Finds test commands from project files
- **Multi-Language Support**: Go, Node.js, Python, Rust, Java (Maven/Gradle), PHP
- **Test-First PRs**: Only creates PR if tests pass
- **Automatic Rollback**: Cancels changes if tests fail
- **Test Results in PRs**: Includes test status in pull request description

**Supported Frameworks:**

| Language | Detection File | Command |
|----------|---------------|---------|
| Node.js | package.json | `npm test` |
| Go | go.mod | `go test ./...` |
| Python | requirements.txt | `python -m pytest` |
| Rust | Cargo.toml | `cargo test` |
| Java (Maven) | pom.xml | `mvn test` |
| Java (Gradle) | build.gradle | `gradle test` |
| PHP | composer.json | `php vendor/bin/phpunit` |

**Example Flow:**
```
ðŸ§ª Checking for tests...
Found test command: go test ./...
âœ“ All tests passed!
```

If tests fail:
```
ðŸ§ª Checking for tests...
Found test command: npm test

âŒ Tests failed! Not creating PR.
Test output:
FAIL src/utils.test.js
  âœ• calculateTotal returns correct sum

Error: tests failed after applying changes
```

## Technical Implementation

### analytics.go
New file providing session tracking:
- `SessionAnalytics` struct with mutex for thread-safe access
- `RecordAPICall(service)` - Tracks each AI request
- `RecordIssueHandled()` - Counts processed issues
- `RecordPRCreated()` - Counts created pull requests
- `RecordQuestionAsked()` - Counts bot questions
- `EstimateCostForIssues(count, service)` - Calculates costs
- `PrintCostEstimate()` - Shows warning before expensive operations
- `PrintSummary()` - Displays end-of-session dashboard

### tests.go
New file for test detection and execution:
- `TestRunner` struct for managing test operations
- `DetectTestCommand()` - Scans project for test files
- `RunTests()` - Executes detected test command
- `Execute()` - Returns `TestResult` with pass/fail status

### Integration Points
1. **AI Clients** (`ai.go`):
   - Added `SetAnalytics()` method to OpenAIClient, XAIClient, OllamaClient
   - Each `AnalyzeAndFix()` call now records API usage

2. **Main Flow** (`main.go`):
   - Creates `SessionAnalytics` at start of `run()`
   - Shows cost estimate before processing all issues
   - Runs tests after applying file changes
   - Displays session summary at end
   - Records metrics throughout processing

## Use Cases

### 1. Development Teams
"We want to use the bot but need to control costs"
- Set daily/weekly budget
- Monitor via session summaries
- Get warnings before expensive operations

### 2. Open Source Maintainers
"I can't risk breaking working code"
- Tests run automatically before every PR
- Failed tests prevent bad fixes
- Test results visible in PR for reviewers

### 3. Enterprise Deployments
"We need audit trails and accountability"
- Session analytics provide complete history
- Track bot effectiveness (PRs vs questions)
- Measure ROI with cost vs issues resolved

## Upgrade Path

### From v1.1.0
No breaking changes. Simply replace the binary:
```bash
# Download new release
wget https://github.com/pefman/Mr-Code-Fixer/releases/download/v1.2.0/mr-code-fixer_OS_ARCH.tar.gz
tar -xzf mr-code-fixer_OS_ARCH.tar.gz
./mr-code-fixer
```

Your existing config (`~/.mr-code-fixer.json`) works as-is.

### New Behavior
- You'll see cost estimates when fixing multiple issues
- You'll see test execution logs (if tests exist)
- You'll see session summaries after each run
- PRs will include test result sections

## Configuration

No new config options needed. Analytics and test execution are automatic.

### Cost Per Call Defaults
```go
chatgpt/openai: $0.002
grok/xai:       $0.001
ollama:         $0.000 (free)
```

These are conservative estimates. Actual costs depend on:
- Token usage (longer issues = higher cost)
- Model selection (GPT-4 > GPT-3.5)
- Provider pricing (check latest rates)

## Performance Impact

- **Memory**: +minimal (SessionAnalytics is <1KB)
- **Runtime**: +test execution time (varies by project)
- **Network**: No additional API calls
- **Disk**: No changes

## Future Enhancements (Not in v1.2.0)

The following were planned but postponed:
- **Webhook Server**: Real-time issue reactions
- **Built-in Scheduler**: Cron-like automation
- **Custom Test Commands**: Override auto-detection
- **Cost Limits**: Hard caps on spending

These may appear in v1.3.0 based on user feedback.
